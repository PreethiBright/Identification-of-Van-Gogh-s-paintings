{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c726K-6eEwpE"
      },
      "source": [
        "#The Final model - VGG19 and SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9E8vhlt2fdt"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import cv2\n",
        "from prettytable import PrettyTable\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "from skimage.util import view_as_windows\n",
        "from matplotlib.pyplot import imread, imsave\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras.callbacks import ModelCheckpoint,LearningRateScheduler, EarlyStopping, TensorBoard,ReduceLROnPlateau\n",
        "from keras.layers import Activation, Conv2D, Input, Embedding, Reshape, MaxPooling2D,MaxPooling1D, Concatenate, Flatten, Dropout, Dense, Conv1D,MaxPool2D,BatchNormalization\n",
        "import tensorflow as tf\n",
        "import datetime\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.utils import shuffle\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.svm import SVC\n",
        "import keras\n",
        "from keras.applications import *\n",
        "\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
        "from keras.models import Model, load_model\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MeochxW92n-F",
        "outputId": "e183103f-80cb-4e08-f07d-fb21ad53f33a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjMB5JpUnB2b"
      },
      "source": [
        "##Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "th1ACFQP2wsY"
      },
      "source": [
        "#Initialise all the director paths and fetch the filenames from this directory. \n",
        "#The dataset consists of images belonging to Van Gogh and other artists. The images are segregated into separate folders for train and test.\n",
        "#The train directory and test directory each have two folders - vg and nvg. \n",
        "#vg folder has images belonging to Van Gogh\n",
        "#nvg folder has images belonginh to Non Van Gogh\n",
        "\n",
        "\n",
        "#directory paths\n",
        "rootdir = '/content/drive/MyDrive/Colab Notebooks/29. Identification of Van Gogh paintings/vgdb_2016/vgdb_2016'\n",
        "\n",
        "#Only test data\n",
        "testdir = rootdir + '/test'\n",
        "testdir_vg = testdir + '/vg'\n",
        "testdir_nvg = testdir + '/nvg'\n",
        "\n",
        "#filenames\n",
        "test_vg_data = os.listdir(testdir_vg)\n",
        "test_nvg_data = os.listdir(testdir_nvg)\n",
        "\n",
        "#Models\n",
        "\n",
        "#vgg19 model\n",
        "vgg19model = VGG19(include_top = False, weights = 'imagenet')\n",
        "\n",
        "#saved SVM model\n",
        "filename = rootdir+'/final_model_svm'\n",
        "clf = pickle.load(open(filename, 'rb'))\n"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQSjV-ZtD3Y4"
      },
      "source": [
        "##Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_CblbUF37NX"
      },
      "source": [
        "#Fusion methods \n",
        "\n",
        "''',\n",
        "Find the farthest point from the prediction probabilities for each image\n",
        "'''\n",
        "def agg_pred_far(pred):\n",
        "\n",
        "  arr_pos = []\n",
        "  arr_neg = []\n",
        "  \n",
        "  for predItem in pred:\n",
        "    if(predItem >= 0):\n",
        "      arr_pos.append(predItem)\n",
        "    else:\n",
        "      arr_neg.append(predItem)\n",
        "\n",
        "  \n",
        "  max_pos = np.max(arr_pos) if(len(arr_pos) > 0) else 0  \n",
        "  \n",
        "  max_neg = np.abs(np.min(arr_neg)) if(len(arr_neg) > 0) else 0\n",
        "\n",
        "  cl = 1 if(max_pos > max_neg) else 0\n",
        "  \n",
        "  return cl\n",
        "\n",
        "'''\n",
        "Find the mean from the prediction probabilities for each image\n",
        "'''\n",
        "def agg_pred_mean(pred):\n",
        "  arr_pos = []\n",
        "  arr_neg = []\n",
        "\n",
        "  for predItem in pred:\n",
        "    if(predItem >= 0):\n",
        "      arr_pos.append(predItem)\n",
        "    else:\n",
        "      arr_neg.append(predItem)\n",
        "\n",
        "\n",
        "  #arr_pos = pred[pred >= 0]\n",
        "  avg_pos = np.mean(arr_pos) if(len(arr_pos) > 0) else 0\n",
        "  \n",
        "  #arr_neg = pred[pred <= 0]\n",
        "  avg_neg = np.abs(np.mean(arr_neg)) if(len(arr_neg) > 0) else 0\n",
        "\n",
        "  cl = 1 if(avg_pos > avg_neg) else 0\n",
        "  \n",
        "  return cl\n",
        "\n",
        "'''\n",
        "Find the median from the prediction probabilities for each image\n",
        "'''\n",
        "def agg_pred_median(pred):\n",
        "\n",
        "  arr_pos = []\n",
        "  arr_neg = []\n",
        "\n",
        "  for predItem in pred:\n",
        "    if(predItem >= 0):\n",
        "      arr_pos.append(predItem)\n",
        "    else:\n",
        "      arr_neg.append(predItem)\n",
        "  #arr_pos = pred[pred >= 0]\n",
        "  avg_pos = np.median(arr_pos) if(len(arr_pos) > 0) else 0\n",
        "  \n",
        "  #arr_neg = pred[pred <= 0]\n",
        "  avg_neg = np.abs(np.median(arr_neg)) if(len(arr_neg) > 0) else 0\n",
        "\n",
        "  cl = 1 if(avg_pos > avg_neg) else 0\n",
        "  \n",
        "  return cl\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzF2CNm5mWd2"
      },
      "source": [
        "\n",
        "no_of_patches =20\n",
        "\n",
        "'''This function is used to generate patches for a particular image. \n",
        "The number of patches and patch_size are passed as function parameters.\n",
        "The function generates the number of patches as the given parameter'''\n",
        "def get_patches_for_img(img_path, patch_size, no_of_patches):\n",
        "    \n",
        "    patches = []\n",
        "\n",
        "    #read the image at the given path\n",
        "    img = cv2.imread(img_path, 1)    \n",
        "    image_height = img.shape[0]\n",
        "    image_width = img.shape[1]\n",
        "\n",
        "    #Subtract patch_size from image's height and width to avoid out of bounds error\n",
        "    range_x = image_height - patch_size\n",
        "    range_y = image_width - patch_size\n",
        "\n",
        "    #Generate patches for each image. The number of patches are passed as parameter.\n",
        "    for i in range(no_of_patches):\n",
        "        \n",
        "        #Generate patch from random area of the image\n",
        "        x = np.random.randint(low = 0, high = range_x)\n",
        "        y = np.random.randint(low = 0, high = range_y)\n",
        "\n",
        "        #The patch is calculated by adding the patch_size to both x and y co-ordinates\n",
        "        patch = img[x : x+patch_size, y : y+patch_size, :]\n",
        "        patches.append(patch)\n",
        "\n",
        "    return patches\n",
        "\n",
        "'''This function creates a feature array for a patch. \n",
        "It uses the VGG 19 to pre-process and predict the feature array for the patch. '''\n",
        "def get_patch_feature_vgg19(patch):\n",
        "\n",
        "    patch_input = np.expand_dims(patch, axis = 0)             #add an extra dimension for batch\n",
        "    patch_preprocessed_input = preprocess_input(patch_input)               \n",
        "\n",
        "    p_feature = vgg19model.predict(patch_preprocessed_input)           \n",
        "    p_feature = p_feature.reshape(25088)\n",
        "    \n",
        "    return p_feature\n"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tguFuzkHEAmQ"
      },
      "source": [
        "##Prediction Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-QcC_XqD9RJ"
      },
      "source": [
        "''' This function can be used to obtain the predictions when the filenames, directory paths and actual values are passed.\n",
        "The number of patches by default are 20 but can be changed.\n",
        "The predictions are obtained by reading the image from the given directory path, generate random patches ,\n",
        "use VGG19 to classify the patches and then use SVM to generate probabilities.These probabilities are returned as the \n",
        "model's predictions. \n",
        " '''\n",
        "\n",
        "def get_predictions(filename_list,dirnameArr,no_of_patches=20):\n",
        "  \n",
        "  predictions=[]\n",
        "\n",
        "  for idx,file_name in enumerate(filename_list): \n",
        "    patch_pred = []                                 \n",
        "    \n",
        "    img_path = dirnameArr[idx] + '/' + file_name\n",
        "    patches = get_patches_for_img(img_path, patch_size, no_of_patches)\n",
        "    \n",
        "    for patch in patches:                                            \n",
        "        patch_feature = get_patch_feature_vgg19(patch)\n",
        "        \n",
        "        pred_proba = clf.decision_function([patch_feature])      \n",
        "        \n",
        "        patch_pred.append(pred_proba)  \n",
        "        \n",
        "\n",
        "    predictions.append(patch_pred)                                  \n",
        "    \n",
        "\n",
        "  return  predictions \n"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9ylzUeWvDeC"
      },
      "source": [
        "''' This function can be used to obtain the f1 scores when the filenames, directory paths and actual values are passed.\n",
        "The number of patches by default are 20 but can be changed.\n",
        "The predictions are obtained by reading the image from the given directory path, generate random patches ,\n",
        "use VGG19 to classify the patches and then use SVM to generate probabilities. \n",
        "The F1-scores are computed over three fusion methods - Median, Mean and Far. The results from these three\n",
        "methods are returned. \n",
        " '''\n",
        "\n",
        "def get_metric_f1_score(filename_list,dirnameArr,y_true,no_of_patches=20):\n",
        "  \n",
        "  #get the predictions\n",
        "  predictions = get_predictions(filename_list,dirnameArr,no_of_patches)   \n",
        "\n",
        "  y_pred_mean= []\n",
        "  y_pred_median= []\n",
        "  y_pred_far=[]\n",
        "  f1_score_median=[]\n",
        "  f1_score_mean=[]\n",
        "  f1_score_far = []\n",
        "  \n",
        "  #Compute the F1-scores\n",
        "\n",
        "  for item in predictions:\n",
        "    y_pred_median.append(agg_pred_median(item))\n",
        "    y_pred_mean.append(agg_pred_mean(item))\n",
        "    y_pred_far.append(agg_pred_far(item))\n",
        "    \n",
        "  f1_score_median = f1_score(y_true, y_pred_median)\n",
        "  f1_score_mean = f1_score(y_true, y_pred_mean)\n",
        "  f1_score_far = f1_score(y_true, y_pred_far)\n",
        "  \n",
        "  return f1_score_median,f1_score_mean,f1_score_far"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xsrw2FqM8Zw5"
      },
      "source": [
        "''' This function can be used to obtain the f1 scores when predictions and the actual values are passed.\n",
        "The F1-scores are computed over three fusion methods - Median, Mean and Far. The results from these three\n",
        "methods are returned. \n",
        " '''\n",
        "def get_f1(predictions,y_true):\n",
        "  \n",
        "  y_pred_mean= []\n",
        "  y_pred_median= []\n",
        "  y_pred_far=[]\n",
        "  f1_score_median=[]\n",
        "  f1_score_mean=[]\n",
        "  f1_score_far = []\n",
        "  \n",
        "\n",
        "  for item in predictions:\n",
        "    y_pred_median.append(agg_pred_median(item))\n",
        "    y_pred_mean.append(agg_pred_mean(item))\n",
        "    y_pred_far.append(agg_pred_far(item))\n",
        "    \n",
        "  f1_score_median = f1_score(y_true, y_pred_median)\n",
        "  f1_score_mean = f1_score(y_true, y_pred_mean)\n",
        "  f1_score_far = f1_score(y_true, y_pred_far)\n",
        "  \n",
        "  return f1_score_median,f1_score_mean,f1_score_far"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8Z6onOaEG46"
      },
      "source": [
        "##Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8vnLaZI3VIx",
        "outputId": "887b1740-3970-4a4c-da69-8c525ceb2797"
      },
      "source": [
        "test_data = []\n",
        "test_data.extend(test_vg_data)\n",
        "test_data.extend(test_nvg_data)\n",
        "print(len(test_data))"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "67\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ki4S4CbD3jtZ",
        "outputId": "f328626c-0d3a-4b6a-d259-05718f1fb5d4"
      },
      "source": [
        "y_1 = [1]*25\n",
        "y_0 = [0]*42\n",
        "\n",
        "y_true=[]\n",
        "y_true.extend(y_1)\n",
        "y_true.extend(y_0)\n",
        "print(len(y_true))"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "67\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhX-Tzkx36D5"
      },
      "source": [
        "dirpaths = []\n",
        "\n",
        "vg_path_arr = ['/content/drive/MyDrive/Colab Notebooks/29. Identification of Van Gogh paintings/vgdb_2016/vgdb_2016/test/vg']*25\n",
        "\n",
        "nvg_path_arr = ['/content/drive/MyDrive/Colab Notebooks/29. Identification of Van Gogh paintings/vgdb_2016/vgdb_2016/test/nvg']*42\n",
        "\n",
        "dirpaths.extend(vg_path_arr)\n",
        "dirpaths.extend(nvg_path_arr)"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdlYm4t5ELOI"
      },
      "source": [
        "##VGG19 and SVM on Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4pKOKcI25TK"
      },
      "source": [
        "pred_values = get_predictions(test_data,dirpaths)"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJfCeKvJ8xxv",
        "outputId": "a64e4c88-2618-4581-fb6f-84e671708f0d"
      },
      "source": [
        "f1_median,f1_mean,f1_far,y_med,y_mean,y_far = get_f1(pred_values,y_true)\n",
        "print(\"F1 scores with different Fusion methods\")\n",
        "print(\"=\"*200)\n",
        "print(\"F1 score for test data - Median is \", f1_median)\n",
        "print(\"F1 score for test data - Mean is\", f1_mean)\n",
        "print(\"F1 score for test data - Far is\", f1_far)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 scores with different Fusion methods\n",
            "========================================================================================================================================================================================================\n",
            "F1 score for test data - Median is  0.9056603773584904\n",
            "F1 score for test data - Mean is 0.888888888888889\n",
            "F1 score for test data - Far is 0.8846153846153846\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLkReif1A-gB"
      },
      "source": [
        "Various models were implemented to find the model which can most accurately predict Van Gogh's paintings. The models that were implemented include, VGG19,ResNet, EfficientNet and their customised versions. The best performing was however VGG19.\n",
        "\n",
        "All models gave satisfying scores of over 80%\n",
        "\n",
        "Once again, here VGG19 gives good F1 score of 0.91 for the test data.\n",
        "\n",
        "With the help of transfer learning with VGG19, we can classify the paintings of VanGogh and other artists,\n"
      ]
    }
  ]
}