{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Post Quantization.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "buaxfuvBz9Gs"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import cv2\n",
        "from prettytable import PrettyTable\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "from skimage.util import view_as_windows\n",
        "from matplotlib.pyplot import imread, imsave\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras.callbacks import ModelCheckpoint,LearningRateScheduler, EarlyStopping, TensorBoard,ReduceLROnPlateau\n",
        "from keras.layers import Activation, Conv2D, Input, Embedding, Reshape, MaxPooling2D,MaxPooling1D, Concatenate, Flatten, Dropout, Dense, Conv1D,MaxPool2D,BatchNormalization\n",
        "import tensorflow as tf\n",
        "import datetime\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.utils import shuffle\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.svm import SVC\n",
        "import keras\n",
        "from keras.applications import *\n",
        "\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
        "from keras.models import Model, load_model\n",
        "import pickle\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "su5-yHF20HSf",
        "outputId": "0da4eed8-b6ca-43e5-de5e-d7ce688efa8b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTDQ9kwy0KaJ"
      },
      "source": [
        "#Initialise all the director paths and fetch the filenames from this directory. \n",
        "#The dataset consists of images belonging to Van Gogh and other artists. The images are segregated into separate folders for train and test.\n",
        "#The train directory and test directory each have two folders - vg and nvg. \n",
        "#vg folder has images belonging to Van Gogh\n",
        "#nvg folder has images belonginh to Non Van Gogh\n",
        "\n",
        "\n",
        "rootdir = '/content/drive/MyDrive/Colab Notebooks/29. Identification of Van Gogh paintings/vgdb_2016/vgdb_2016'\n",
        "\n",
        "#Train data\n",
        "traindir = rootdir + '/train'\n",
        "traindir_vg = traindir + '/vg'\n",
        "traindir_nvg = traindir + '/nvg'\n",
        "\n",
        "#Test data\n",
        "testdir = rootdir + '/test'\n",
        "testdir_vg = testdir + '/vg'\n",
        "testdir_nvg = testdir + '/nvg'\n",
        "\n",
        "train_vg_data = os.listdir(traindir_vg)\n",
        "train_nvg_data = os.listdir(traindir_nvg)\n",
        "\n",
        "test_vg_data = os.listdir(testdir_vg)\n",
        "test_nvg_data = os.listdir(testdir_nvg)\n",
        "\n",
        "dir_patch_tr=traindir+'/patches'\n",
        "dir_patch_te=testdir+'/patches'\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpRHiWybxEB0"
      },
      "source": [
        "filename = rootdir+'/final_model_svm'\n",
        "clf = pickle.load(open(filename, 'rb'))"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqXpcgtYFGvW"
      },
      "source": [
        "##Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYj6MsQ4Uq9j",
        "outputId": "dacc8134-54a3-4e88-8350-4c08bb0ddd6c"
      },
      "source": [
        "test_data = []\n",
        "test_data.extend(test_vg_data)\n",
        "test_data.extend(test_nvg_data)\n",
        "print(len(test_data))\n",
        "\n",
        "\n",
        "y_1 = [1]*25\n",
        "y_0 = [0]*42\n",
        "\n",
        "y_true=[]\n",
        "y_true.extend(y_1)\n",
        "y_true.extend(y_0)\n",
        "print(len(y_true))\n",
        "\n",
        "dirpaths = []\n",
        "\n",
        "vg_path_arr = ['/content/drive/MyDrive/Colab Notebooks/29. Identification of Van Gogh paintings/vgdb_2016/vgdb_2016/test/vg']*25\n",
        "\n",
        "nvg_path_arr = ['/content/drive/MyDrive/Colab Notebooks/29. Identification of Van Gogh paintings/vgdb_2016/vgdb_2016/test/nvg']*42\n",
        "\n",
        "dirpaths.extend(vg_path_arr)\n",
        "dirpaths.extend(nvg_path_arr)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "67\n",
            "67\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "venl-pqU6J1g",
        "outputId": "295fa588-216d-4926-8621-c14efac1e947"
      },
      "source": [
        "import random\n",
        "sample_test_indices = random.sample(range(1, 66), 20)\n",
        "\n",
        "print(len(sample_test_indices))\n",
        "print(sample_test_indices)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20\n",
            "[10, 18, 43, 7, 41, 5, 44, 50, 26, 21, 46, 49, 47, 32, 20, 25, 62, 8, 30, 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5NogUSx68ej"
      },
      "source": [
        "sample_test_data = []\n",
        "sample_y_true = []\n",
        "sample_dir_path = []\n",
        "\n",
        "for idx in sample_test_indices:\n",
        "  sample_test_data.append(test_data[idx])\n",
        "  sample_y_true.append(y_true[idx])\n",
        "  sample_dir_path.append(dirpaths[idx])"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ln7BidlmxP72"
      },
      "source": [
        "##VGG19"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRkKtT95Qq0-"
      },
      "source": [
        "vgg19model = VGG19(include_top = False, weights = 'imagenet')"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpWLIu9vwbqu",
        "outputId": "01639331-43df-4610-bda4-29ac526ff1ac"
      },
      "source": [
        "vgg19model.save(rootdir+'/vgg19model_pre_tflite.h5')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgkqdfxrwJ1H",
        "outputId": "80d93325-17ce-41ea-8653-8e43b361bdb7"
      },
      "source": [
        "fileSize = os.path.getsize(rootdir+'/vgg19model_pre_tflite.h5')\n",
        "print('File size: ' + str(round(fileSize / (1024 * 1024), 3)) + ' Megabytes')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File size: 76.455 Megabytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBP6Kew72pBG",
        "outputId": "1c8b44b9-aa6a-46cb-8f90-e7fca4bed11b"
      },
      "source": [
        "#pred_values = get_predictions(test_data,dirpaths,False)\n",
        "pred_values = get_predictions(sample_test_data,sample_dir_path,False,no_of_patches=5)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:13<00:00,  1.53it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-4oflx1xl4V",
        "outputId": "5efc1c71-175e-4c07-b9ab-819120e88c8f"
      },
      "source": [
        "f1_median,f1_mean,f1_far = get_f1(pred_values,sample_y_true)\n",
        "print(\"F1 scores with different Fusion methods\")\n",
        "print(\"=\"*200)\n",
        "print(\"F1 score for test data - Median is \", f1_median)\n",
        "print(\"F1 score for test data - Mean is\", f1_mean)\n",
        "print(\"F1 score for test data - Far is\", f1_far)\n"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 scores with different Fusion methods\n",
            "========================================================================================================================================================================================================\n",
            "F1 score for test data - Median is  0.875\n",
            "F1 score for test data - Mean is 0.875\n",
            "F1 score for test data - Far is 0.9333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZpcEJkE2r4t"
      },
      "source": [
        "##Post Quantization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guYc4FL83dDz"
      },
      "source": [
        "vgg19model1 = VGG19(include_top = False, weights = 'imagenet')"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0mDpmrp2wXu",
        "outputId": "9362925f-34fa-40ff-b7a6-cac96b1c5a23"
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(vgg19model1)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "vgg19_tflite_model = converter.convert()\n",
        "open(rootdir+'/custom_vgg_model.tflite', \"wb\").write(vgg19_tflite_model)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpfh8crd4q/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpfh8crd4q/assets\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20161440"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNM36hIh3aKM",
        "outputId": "6a4bf263-3c0b-4d1c-c20c-ca739683a3cb"
      },
      "source": [
        "fileSize = os.path.getsize(rootdir+'/custom_vgg_model.tflite')\n",
        "print('File size: ' + str(round(fileSize / (1024 * 1024), 3)) + ' Megabytes')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File size: 19.227 Megabytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uQEu5FP3iq8",
        "outputId": "1e44991e-d341-4e6c-fe61-8e30d9df4934"
      },
      "source": [
        "interpreter = tf.lite.Interpreter(model_content=vgg19_tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details= interpreter.get_output_details()\n",
        "print(\"Input Shape\", input_details[0]['shape'])\n",
        "print(\"Input Type\", input_details[0]['dtype'])\n",
        "print(\"Output Shape\", output_details[0]['shape'])\n",
        "print(\"Output Type\", output_details[0]['dtype'])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Shape [1 1 1 3]\n",
            "Input Type <class 'numpy.float32'>\n",
            "Output Shape [  1   0   0 512]\n",
            "Output Type <class 'numpy.float32'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brYGsY094jeT"
      },
      "source": [
        "interpreter.resize_tensor_input(input_details[0]['index'],(1, 224, 224, 3))\n",
        "interpreter.resize_tensor_input(output_details[0]['index'], (1, 25088))\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cDOCF1Thek5",
        "outputId": "5a247e08-8d99-4bac-bfaf-8e632f04544c"
      },
      "source": [
        "pred_values_tflite = get_predictions(sample_test_data,sample_dir_path,True,no_of_patches=5)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [1:37:01<00:00, 291.09s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMhf5rW9zWDe"
      },
      "source": [
        "Tflite took more than 20 minutes to predict for the 20 patches per image. Since we have 67 images, it would have taken more than 10 hours to complete execution. Hence, reduced the number of patches to 5."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKJv84fmVL2Y",
        "outputId": "dae7eec3-5ff9-44f2-ae27-f9d64172e338"
      },
      "source": [
        "f1_median,f1_mean,f1_far = get_f1(pred_values_tflite,sample_y_true)\n",
        "print(\"F1 scores with different Fusion methods\")\n",
        "print(\"=\"*200)\n",
        "print(\"F1 score for test data - Median is \", f1_median)\n",
        "print(\"F1 score for test data - Mean is\", f1_mean)\n",
        "print(\"F1 score for test data - Far is\", f1_far)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 scores with different Fusion methods\n",
            "========================================================================================================================================================================================================\n",
            "F1 score for test data - Median is  0.875\n",
            "F1 score for test data - Mean is 0.875\n",
            "F1 score for test data - Far is 0.875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yK5jVS45VVPm"
      },
      "source": [
        "##Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yz92E7J_Rji4"
      },
      "source": [
        "no_of_patches =20\n",
        "\n",
        "'''This function is used to generate patches for a particular image. \n",
        "The number of patches and patch_size are passed as function parameters.\n",
        "The function generates the number of patches as the given parameter'''\n",
        "def get_patches_for_img(img_path, patch_size, no_of_patches):\n",
        "    \n",
        "    patches = []\n",
        "\n",
        "    #read the image at the given path\n",
        "    img = cv2.imread(img_path, 1)    \n",
        "    image_height = img.shape[0]\n",
        "    image_width = img.shape[1]\n",
        "\n",
        "    #Subtract patch_size from image's height and width to avoid out of bounds error\n",
        "    range_x = image_height - patch_size\n",
        "    range_y = image_width - patch_size\n",
        "\n",
        "    #Generate patches for each image. The number of patches are passed as parameter.\n",
        "    for i in range(no_of_patches):\n",
        "        \n",
        "        #Generate patch from random area of the image\n",
        "        x = np.random.randint(low = 0, high = range_x)\n",
        "        y = np.random.randint(low = 0, high = range_y)\n",
        "\n",
        "        #The patch is calculated by adding the patch_size to both x and y co-ordinates\n",
        "        patch = img[x : x+patch_size, y : y+patch_size, :]\n",
        "        patches.append(patch)\n",
        "\n",
        "    return patches\n",
        "\n",
        "'''This function creates a feature array for a patch. \n",
        "It uses the VGG 19 to pre-process and predict the feature array for the patch. '''\n",
        "def get_patch_feature_vgg19_tflite(patch):  \n",
        "    \n",
        "    patch_pre_list = []\n",
        "\n",
        "    #for patch in patches:\n",
        "\n",
        "    patch_input = np.expand_dims(patch, axis = 0)             #add an extra dimension for batch\n",
        "    patch_preprocessed_input = preprocess_input(patch_input)    \n",
        "\n",
        "    #  patch_pre_list.append(patch_preprocessed_input)  \n",
        "    interpreter.set_tensor(input_details[0]['index'], patch_preprocessed_input)\n",
        "    interpreter.invoke()\n",
        "    \n",
        "    tflite_model_predictions = interpreter.get_tensor(output_details[0]['index'])    \n",
        "    \n",
        "    p_feature = tflite_model_predictions.reshape(25088)\n",
        "\n",
        "    return p_feature\n",
        "\n",
        "'''This function creates a feature array for a patch. \n",
        "It uses the VGG 19 to pre-process and predict the feature array for the patch. '''\n",
        "def get_patch_feature_vgg19(patch):\n",
        "    \n",
        "    patch_input = np.expand_dims(patch, axis = 0)             #add an extra dimension for batch\n",
        "    patch_preprocessed_input = preprocess_input(patch_input)               \n",
        "\n",
        "    p_feature = vgg19model.predict(patch_preprocessed_input) \n",
        "    p_feature = p_feature.reshape(25088)\n",
        "\n",
        "    return p_feature\n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ythm-4YUulyU"
      },
      "source": [
        "#Fusion methods \n",
        "\n",
        "''',\n",
        "Find the farthest point from the prediction probabilities for each image\n",
        "'''\n",
        "def agg_pred_far(pred):\n",
        "\n",
        "  arr_pos = []\n",
        "  arr_neg = []\n",
        "  \n",
        "  for predItem in pred:\n",
        "    if(predItem >= 0):\n",
        "      arr_pos.append(predItem)\n",
        "    else:\n",
        "      arr_neg.append(predItem)\n",
        "\n",
        "  \n",
        "  max_pos = np.max(arr_pos) if(len(arr_pos) > 0) else 0  \n",
        "  \n",
        "  max_neg = np.abs(np.min(arr_neg)) if(len(arr_neg) > 0) else 0\n",
        "\n",
        "  cl = 1 if(max_pos > max_neg) else 0\n",
        "  \n",
        "  return cl\n",
        "\n",
        "'''\n",
        "Find the mean from the prediction probabilities for each image\n",
        "'''\n",
        "def agg_pred_mean(pred):\n",
        "  arr_pos = []\n",
        "  arr_neg = []\n",
        "\n",
        "  for predItem in pred:\n",
        "    if(predItem >= 0):\n",
        "      arr_pos.append(predItem)\n",
        "    else:\n",
        "      arr_neg.append(predItem)\n",
        "\n",
        "\n",
        "  #arr_pos = pred[pred >= 0]\n",
        "  avg_pos = np.mean(arr_pos) if(len(arr_pos) > 0) else 0\n",
        "  \n",
        "  #arr_neg = pred[pred <= 0]\n",
        "  avg_neg = np.abs(np.mean(arr_neg)) if(len(arr_neg) > 0) else 0\n",
        "\n",
        "  cl = 1 if(avg_pos > avg_neg) else 0\n",
        "  \n",
        "  return cl\n",
        "\n",
        "'''\n",
        "Find the median from the prediction probabilities for each image\n",
        "'''\n",
        "def agg_pred_median(pred):\n",
        "\n",
        "  arr_pos = []\n",
        "  arr_neg = []\n",
        "\n",
        "  for predItem in pred:\n",
        "    if(predItem >= 0):\n",
        "      arr_pos.append(predItem)\n",
        "    else:\n",
        "      arr_neg.append(predItem)\n",
        "  #arr_pos = pred[pred >= 0]\n",
        "  avg_pos = np.median(arr_pos) if(len(arr_pos) > 0) else 0\n",
        "  \n",
        "  #arr_neg = pred[pred <= 0]\n",
        "  avg_neg = np.abs(np.median(arr_neg)) if(len(arr_neg) > 0) else 0\n",
        "\n",
        "  cl = 1 if(avg_pos > avg_neg) else 0\n",
        "  \n",
        "  return cl\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRLBa0ghVJEv"
      },
      "source": [
        "##Prediction Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ftu-fixiUqRf"
      },
      "source": [
        "''' This function can be used to obtain the predictions when the filenames, directory paths and actual values are passed.\n",
        "The number of patches by default are 20 but can be changed.\n",
        "The predictions are obtained by reading the image from the given directory path, generate random patches ,\n",
        "use VGG19 to classify the patches and then use SVM to generate probabilities.These probabilities are returned as the \n",
        "model's predictions. \n",
        " '''\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "patch_size = 224                            #patch_size for vgg19 model\n",
        "def get_predictions(filename_list,dirnameArr, isTflite,no_of_patches=20):\n",
        "  \n",
        "  predictions=[]\n",
        "  \n",
        "  idx = 0\n",
        "  for file_name in tqdm(filename_list): \n",
        "    patch_pred = []\n",
        "                         \n",
        "    \n",
        "    img_path = dirnameArr[idx] + '/' + file_name\n",
        "    patches = get_patches_for_img(img_path, patch_size, no_of_patches)\n",
        "    \n",
        "    idx = idx + 1\n",
        "    for patch in patches:                                \n",
        "\n",
        "        if(isTflite):\n",
        "            patch_feature = get_patch_feature_vgg19_tflite(patch)\n",
        "        else:\n",
        "            patch_feature = get_patch_feature_vgg19(patch)\n",
        "        \n",
        "        pred_proba = clf.decision_function([patch_feature])      \n",
        "        \n",
        "        patch_pred.append(pred_proba)  \n",
        "        \n",
        "\n",
        "    predictions.append(patch_pred)                                  \n",
        "    \n",
        "\n",
        "  return  predictions \n",
        "\n",
        "''' This function can be used to obtain the f1 scores when the filenames, directory paths and actual values are passed.\n",
        "The number of patches by default are 20 but can be changed.\n",
        "The predictions are obtained by reading the image from the given directory path, generate random patches ,\n",
        "use VGG19 to classify the patches and then use SVM to generate probabilities. \n",
        "The F1-scores are computed over three fusion methods - Median, Mean and Far. The results from these three\n",
        "methods are returned. \n",
        " '''\n",
        "\n",
        "def get_metric_f1_score(filename_list,dirnameArr,y_true,no_of_patches=20):\n",
        "  \n",
        "  #get the predictions\n",
        "  predictions = get_predictions(filename_list,dirnameArr,no_of_patches)   \n",
        "\n",
        "  y_pred_mean= []\n",
        "  y_pred_median= []\n",
        "  y_pred_far=[]\n",
        "  f1_score_median=[]\n",
        "  f1_score_mean=[]\n",
        "  f1_score_far = []\n",
        "  \n",
        "  #Compute the F1-scores\n",
        "\n",
        "  for item in predictions:\n",
        "    y_pred_median.append(agg_pred_median(item))\n",
        "    y_pred_mean.append(agg_pred_mean(item))\n",
        "    y_pred_far.append(agg_pred_far(item))\n",
        "    \n",
        "  f1_score_median = f1_score(y_true, y_pred_median)\n",
        "  f1_score_mean = f1_score(y_true, y_pred_mean)\n",
        "  f1_score_far = f1_score(y_true, y_pred_far)\n",
        "  \n",
        "  return f1_score_median,f1_score_mean,f1_score_far\n",
        "\n",
        "\n",
        "''' This function can be used to obtain the f1 scores when predictions and the actual values are passed.\n",
        "The F1-scores are computed over three fusion methods - Median, Mean and Far. The results from these three\n",
        "methods are returned. \n",
        " '''\n",
        "def get_f1(predictions,y_true):\n",
        "  \n",
        "  y_pred_mean= []\n",
        "  y_pred_median= []\n",
        "  y_pred_far=[]\n",
        "  f1_score_median=[]\n",
        "  f1_score_mean=[]\n",
        "  f1_score_far = []\n",
        "  \n",
        "\n",
        "  for item in predictions:\n",
        "    y_pred_median.append(agg_pred_median(item))\n",
        "    y_pred_mean.append(agg_pred_mean(item))\n",
        "    y_pred_far.append(agg_pred_far(item))\n",
        "    \n",
        "  f1_score_median = f1_score(y_true, y_pred_median)\n",
        "  f1_score_mean = f1_score(y_true, y_pred_mean)\n",
        "  f1_score_far = f1_score(y_true, y_pred_far)\n",
        "  \n",
        "  return f1_score_median,f1_score_mean,f1_score_far"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49bA6m0nDa_1"
      },
      "source": [
        "Observations:\n",
        "\n",
        "1. The file size before quantization was around 76 MB. After quantization, the file size shrunk to 19MB i.e it became 4 times smaller than the original file.\n",
        "\n",
        "2. Performance wise, both the models i.e original model and the quantized model yielded good results. Owing to the extremely long execution time of the quantized model, the number of patches had to be reduced to 5 from 20. Even with fewer patches, both models yielded good results. Hence, we can say that the quantization did not drastically reduce the effectiveness of the model.\n",
        "\n",
        "3. Tflite took more than 20 minutes to predict for the 20 patches per image. Since we have 67 images, it would have taken more than 10 hours to complete execution. Hence, reduced the number of patches to 5."
      ]
    }
  ]
}